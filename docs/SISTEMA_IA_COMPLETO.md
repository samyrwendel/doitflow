# ğŸ¤– ConfiguraÃ§Ã£o Completa do Sistema de IA

## ğŸ”‘ **API Key e Provedor**

### **Provedor de IA:** Groq
- **API Key:** `YOUR_GROQ_API_KEY`
- **LocalizaÃ§Ã£o:** Arquivo `.env` na raiz do projeto
- **VariÃ¡vel:** `GROQ_API_KEY`

### **Por que Groq?**
- âš¡ **Ultra-rÃ¡pido**: Inference em tempo real
- ğŸ’° **Custo-efetivo**: PreÃ§os competitivos
- ğŸ¯ **Especializado**: Otimizado para Llama e Whisper
- ğŸ”’ **ConfiÃ¡vel**: Infraestrutura robusta

---

## ğŸ§  **Modelos de IA Utilizados**

### **1. ğŸ“ TranscriÃ§Ã£o de Ãudio**
```javascript
// Modelo Whisper para Speech-to-Text
model: 'whisper-large-v3'
temperature: 0.0  // MÃ¡xima precisÃ£o
language: 'pt'    // PortuguÃªs brasileiro
```

**CaracterÃ­sticas:**
- **PrecisÃ£o**: Estado da arte para portuguÃªs
- **Suporte**: MÃºltiplos formatos de Ã¡udio
- **Robustez**: Funciona com ruÃ­do de fundo
- **Velocidade**: Processamento otimizado

### **2. ğŸ’¬ Chat/RAG (Resposta a Perguntas)**
```javascript
// Modelo Llama para Text Generation
model: "llama-3.1-8b-instant"
temperature: 0.2  // Busca inteligente (mais preciso)
temperature: 0.3  // Busca tradicional (mais criativo)
max_tokens: 1000  // Limite de resposta
```

**CaracterÃ­sticas:**
- **InteligÃªncia**: 8 bilhÃµes de parÃ¢metros
- **Velocidade**: VersÃ£o "instant" otimizada
- **MultilÃ­ngue**: Excelente em portuguÃªs
- **Contexto**: AtÃ© 8k tokens de contexto

---

## ğŸ“‹ **Sistema de Prompts**

### **ğŸ¯ Busca Inteligente (Nova Arquitetura)**
```javascript
const systemPrompt = `VocÃª Ã© um assistente inteligente especializado em analisar documentos. 
Responda perguntas baseado exclusivamente no contexto fornecido.

Baseado no documento "${documento.title}", use as seguintes informaÃ§Ãµes relevantes:

[1] Primeiro chunk relevante...
[2] Segundo chunk relevante...
[3] Terceiro chunk relevante...

---

Pergunta do usuÃ¡rio: ${message}

InstruÃ§Ãµes:
- Use apenas as informaÃ§Ãµes do contexto fornecido
- Seja preciso e objetivo
- Se nÃ£o souber, diga claramente que a informaÃ§Ã£o nÃ£o estÃ¡ disponÃ­vel
- Cite os trechos relevantes quando apropriado`;
```

### **ğŸ“š Busca Tradicional (Fallback)**
```javascript
const systemPrompt = `VocÃª Ã© um assistente inteligente que responde perguntas baseado no contexto fornecido.

Contexto:
[Documento A]: ConteÃºdo relevante...
[Documento B]: Mais conteÃºdo...

Pergunta do usuÃ¡rio: ${message}

Responda de forma clara e concisa, citando as fontes quando relevante.`;
```

---

## âš™ï¸ **ConfiguraÃ§Ãµes Detalhadas**

### **ğŸ”§ ParÃ¢metros de TranscriÃ§Ã£o**
```javascript
{
  model: 'whisper-large-v3',
  file: audioFile,
  temperature: 0.0,        // MÃ¡xima precisÃ£o
  language: 'pt',          // PortuguÃªs
  response_format: 'json'  // Formato estruturado
}
```

### **ğŸ›ï¸ ParÃ¢metros de Chat**

#### **Busca Inteligente:**
```javascript
{
  model: "llama-3.1-8b-instant",
  temperature: 0.2,      // Menos criativo, mais preciso
  max_tokens: 1000,      // Resposta mÃ©dia
  messages: [
    {
      role: "system",
      content: systemPrompt  // Prompt estruturado
    }
  ]
}
```

#### **Busca Tradicional:**
```javascript
{
  model: "llama-3.1-8b-instant", 
  temperature: 0.3,      // Pouco mais criativo
  max_tokens: 1000,      // Resposta mÃ©dia
  messages: [...]
}
```

---

## ğŸ” **Algoritmo de Busca SemÃ¢ntica**

### **ğŸ§  Busca Inteligente (Nova)**
```javascript
function findMostRelevantChunks(query, ragDocuments, maxChunks = 5) {
  // 1. Extrair palavras-chave da pergunta
  const queryWords = query.toLowerCase()
    .replace(/[^\w\s]/g, '')
    .split(/\s+/)
    .filter(word => word.length > 2);

  // 2. Scoring por relevÃ¢ncia
  queryWords.forEach(word => {
    // CorrespondÃªncia exata: +2 pontos
    // CorrespondÃªncia parcial: +1 ponto
    // MÃºltiplas palavras-chave: +3 pontos
    // PosiÃ§Ã£o no documento: bonus
  });

  // 3. Retornar apenas top 5 chunks mais relevantes
  return scoredChunks.slice(0, 5);
}
```

### **ğŸ“Š Busca Tradicional**
```javascript
function calculateSimilarity(text1, text2) {
  // SinÃ´nimos prÃ©-definidos
  const synonyms = {
    'criou': ['desenvolvedor', 'criador', 'desenvolveu'],
    'horÃ¡rio': ['hora', 'funcionamento', 'perÃ­odo'],
    // ... mais sinÃ´nimos
  };

  // Score baseado em correspondÃªncias + sinÃ´nimos
  // NormalizaÃ§Ã£o e threshold de relevÃ¢ncia
}
```

---

## ğŸ¯ **Fluxo de Processamento**

### **1. ğŸ“¤ Input do UsuÃ¡rio**
```
Pergunta: "Qual o horÃ¡rio de funcionamento?"
RAG selecionado: "Manual-Empresa-2024"
```

### **2. ğŸ” Busca SemÃ¢ntica**
```javascript
// Sistema encontra chunks relevantes:
[
  "Funcionamos de segunda a sexta...",
  "HorÃ¡rio de atendimento: 9h Ã s 18h...", 
  "Nos finais de semana estamos fechados..."
]
```

### **3. ğŸ§  GeraÃ§Ã£o de Resposta**
```javascript
// Prompt enviado para Llama:
"Com base no documento 'Manual-Empresa-2024':
[1] Funcionamos de segunda a sexta...
[2] HorÃ¡rio de atendimento: 9h Ã s 18h...
[3] Nos finais de semana estamos fechados...

Pergunta: Qual o horÃ¡rio de funcionamento?"
```

### **4. âœ… Resposta Final**
```
"Com base no manual da empresa, nosso horÃ¡rio de funcionamento Ã©:
- Segunda a sexta: 9h Ã s 18h
- Finais de semana: Fechado

Fonte: Manual-Empresa-2024, seÃ§Ãµes de atendimento."
```

---

## ğŸ“Š **EstatÃ­sticas do Sistema**

### **âš¡ Performance**
- **TranscriÃ§Ã£o**: ~5-10s para Ã¡udios de 1 minuto
- **Busca**: ~200ms para encontrar chunks relevantes  
- **GeraÃ§Ã£o**: ~1-3s para resposta completa
- **PrecisÃ£o**: ~95% em portuguÃªs brasileiro

### **ğŸ’¾ Limites**
- **Ãudio mÃ¡ximo**: 50MB por arquivo
- **Contexto**: 8.000 tokens (~6.000 palavras)
- **Resposta**: 1.000 tokens (~750 palavras)
- **Chunks por busca**: MÃ¡ximo 5 (otimizado)

### **ğŸ¯ OtimizaÃ§Ãµes**
- **Chunking adaptativo**: 1000-1500 caracteres
- **Cache de Ã­ndices**: GeraÃ§Ã£o automÃ¡tica por documento
- **Busca por relevÃ¢ncia**: Score semÃ¢ntico otimizado
- **Fallback**: Sistema duplo de busca

---

**Sistema totalmente otimizado para mÃ¡xima precisÃ£o e velocidade!** ğŸš€ğŸ¯